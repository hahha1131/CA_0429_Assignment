## 정렬 알고리즘  

___

### To do  

* 입력 데이터는  
~~~
[32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16348, 32768, 65536, 131072, 262144, 524288, 1048576]
~~~
* 세 가지 경우에 대해 알고리즘 수행 시간 측정하여 그래프로 표현  
   * 정렬된 데이터(위의 배열 그대로 입력)  
   * 랜덤 데이터(위의 배열에서 인덱스와 원소 값 무작위 재배치)  
   * 역 정렬 데이터(배열 원소를 역으로 배치)  
___

### 버블 정렬  

* 이웃하는 숫자와 비교하며 오름차순 또는 내림차순으로 서로의 위치를 교체하며 정렬하는 알고리즘  

#### 버블 정렬 성능 분석
 **<정렬된 데이터의 시간복잡도 계산>**  
* 이중 for문이 실행된다  
* 위 배열의 크기는 인덱스로 0~15(총 크기는 16)이므로 비교 횟수는 16 * 15 / 2 = 120(회) {n(n-1)/2}  
* 안쪽 for문의 if문이 참이라면 자리가 바뀌지 않기 때문에 O(1) 시간 경과  
* 최종 시간복잡도는 O(n^2) * O(1) = O(n^2)  

 **<정렬된 데이터의 비교 횟수와 교체 횟수>**  
* 정렬이 되어 있기에, 비교는 수행하지만 교체는 일어나지 않음
* 따라서 비교 횟수는 120회, 교체 횟수는 0회

 **<랜덤 데이터 시간복잡도 계산>**  
* 버블 정렬의 작동 방식과 수행하는 데에 걸리는 시간은, 배열의 비교 횟수와 교체 횟수에 관계없이 최악의 경우에서의 복잡도인 O(n^2)  

 **<랜덤 데이터의 비교 횟수와 교체 횟수>**  
* 만약 랜덤으로 배열을 섞은 결과가 다음과 같다면

~~~
[64, 32, 512, 256, 5128, 1024, 2048, 131027, 1048576, 262144, 32768, 65536, 4096, 16348, 524288, 8192]
// 앞으로 입력되는 랜덤한 데이터의 형태는 위의 배열과 같다
~~~
* 비교 횟수는 동일하게 120회  
* 교체 횟수는 30회  

 **<역 정렬 데이터의 시간복잡도>**  
* 역시나 O(n^2)  

 **<역 정렬 데이터의 비교 횟수와 교체 횟수>**  
* 비교 횟수 120회  
* 교체 횟수는 120회  

___

### 선택 정렬  

* 입력된 데이터 중 가장 작은 데이터를 선택하여 이전에 이동시킨 가장 작은 데이터를 제외한 배열의 가장 앞으로 이동시키는 알고리즘  

#### 선택 정렬 성능 분석  
 **<정렬된 데이터의 시간복잡도 계산>**  
* 버블 정렬과 같이 두 개의 for문, 내부 for문의 if문(최솟값인지 확인하는 if문)이 참이면 교체 X  
* 따라서, 비교 횟수는 버블 정렬과 동일하게 n(n-1)/2 이므로, 16 * 15 / 2 = 120(회)  
* 정렬이 되어 있기 때문에 교체하는 과정의 시간복잡도는 O(1)  
* 최종 시간복잡도는 O(n^2)  

 **<정렬된 데이터의 비교 횟수와 교체 횟수>**  
* 비교 횟수는 120회  
* 교체 횟수는 0회  

 **<랜덤한 데이터의 시간복잡도 계산>**  
* 각 정렬의 시간복잡도는 최악의 경우에서 도출되는 시간복잡도이기 때문에 데이터의 입력 순서에 상관없이 O(n^2)  

 **<랜덤한 데이터의 비교 횟수와 교체 횟수>**  
* 비교 횟수는 120회  
* 교체 횟수는 8회  

 **<역 정렬 데이터의 시간복잡도>**  
* 위에서 언급한 것과 같이 O(n^2)  

 **<역 정렬 데이터의 비교 횟수와 교체 횟수>**  
* 비교 횟수 120회  
* 교체 횟수 8회  

___

### 삽입 정렬  

* 입력된 데이터를 정렬된 부분과 정렬되지 않은 부분으로 나눈 후에 정렬이 되지 않은 부분의 가장 왼쪽 원소를 정렬된 부분의 적절한 위치에 삽입하여 정렬하는 알고리즘  

#### 삽입 정렬 성능 분석  
 **<정렬된 데이터의 시간복잡도 계산>**  
* 기본적으로 전부 정렬되어 있기 때문에 외부 for문(현재 들고 있는 원소와 정렬된 부분의 특정 원소와의 비교) n-1회 수행
* while문으로 데이터 간의 이동을 한다고 했을 때 정렬된 데이터가 들어온다면, (현재 삽입할 데이터가 정렬된 부분의 비교 데이터보다 크면 수행한다는 조건의) while문이 실행되지 않음, 따라서 시간복잡도 X  
* 최종 시간복잡도는 O(n)  

 **<정렬된 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 15회  
* 교체 횟수 0회  

 **<랜덤한 데이터의 시간복잡도 계산>**
* 거의 역 정렬에 가까운 데이터를 정렬한다면 비교 횟수는 n(n-1)/2  
* 역 정렬에 가깝다면 외부 for문이 한 번씩 수행될 때마다 i + x 번의 이동이 발생
* 따라서 최종 시간복잡도는 O(n^2)

 **<랜덤한 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 15회  
* 이동 횟수 30회  

 **<역 정렬 데이터의 시간복잡도 계산>**  
* 총 비교 횟수는 n(n-1)/2, 역 정렬 데이터는 각 반복 단계마다 한 칸씩 데이터가 이동되어야 한다  
* 이동 횟수도 각 비교 이후의 반복 단계마다 이동해야 하기 때문에 i + x 번의 이동이 발생한다  
* 최종 시간복잡도 O(n^2)  

 **<역 정렬 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 120회  
* 이동 횟수 120회  

___

### 쉘 정렬  

* 삽입 정렬을 이용하여 입력된 데이터 중 가장 작은 데이터를 앞부분으로 이동시키고, 앞부분에 있던 큰 숫자는 뒷부분으로 이동시킨 후에 삽입 정렬을 수행하여 데이터를 정렬하는 알고리즘  

#### 쉘 정렬 성능 분석  
 **<정렬된 데이터의 시간복잡도 계산>**  
* 이후 입력될 역 정렬의 데이터와 정렬된 데이터의 시간복잡도는 삽입 정렬을 기본으로 하는 쉘 정렬의 특성에 따라 삽입 정렬과 같은 시간복잡도를 가진다
* 따라서 정렬된 데이터를 입력했을 때의 시간복잡도는 O(n)  

 **<정렬된 데이터의 비교 횟수와 교체 횟수>**  
* 비교 횟수 15회  
* 교체 횟수 0회  

 **<랜덤한 데이터의 시간복잡도 계산>**  
* 쉘 정렬의 랜덤 데이터 시간복잡도는 정렬된, 역 정렬 데이터를 입력했을 때와 다르게 삽입 정렬과 다른 시간복잡도를 가진다  
* 외부 for문(탐색)을 거친다 n-1  
* 이후 내부 반복문에서 특정 간격만큼 이동하며 데이터가 들어갈 위치를 찾고, 데이터를 교체한다  
* 따라서 시간복잡도는 평균 시간복잡도와 가까운 O(n^1.5)  

 **<랜덤한 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 21회  
* 교체 횟수 7회  

 **<역 정렬 데이터의 시간복잡도 계산>**  
* 비교 횟수 22회  
* 교체 횟수 8회  

___  

### 힙 정렬  

* 최대 힙 트리나 최소 힙 트리를 구성해 정렬하는 알고리즘
* 무조건 오름차순으로 정렬할 것이기 때문에 최소 힙을 구현하여 정렬하면 된다

#### 힙 정렬 성능 분석
 **<정렬된 데이터의 시간복잡도 계산>**  
* 완전 이진 트리를 사용하기 때문에 트리 전체 높이가 log2n이므로 데이터 하나의 상태를 변경할 때마다 log2n의 시간 소요  
* 전체 데이터의 갯수가 n이라고 하면  
* 따라서 시간복잡도는 O(nlog2n)  

 **<정렬된 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수: 힙의 각 레벨마다 n번 비교
* 이동 횟수 16회  

 **<랜덤한 데이터의 시간복잡도 계산>**  
* 힙 정렬은 어떠한 형식의 데이터가 와도 힙을 만드는 과정과 데이터를 비교하여 힙을 트리를 새로 만드는 과정을 똑같이 수행하기 때문에 시간복잡도는 같다  
* 최종 시간복잡도는 O(log2n)  

 **<랜덤한 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수: 힙의 각 레벨마다 n번 비교  
* 이동 횟수 16회  

 **<역 정렬 데이터의 시간복잡도 계산>**  
* 시간복잡도 O(log2n)  

 **<역 정렬 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 동일  
* 이동 횟수 16회

___

### 퀵 정렬  

* 피벗이라는 기준이 되는 데이터 값을 만들고 피벗을 기준으로 작은 요소는 왼쪽, 큰 요소는 오른쪽에 배치하고 각각 분할 정복을 통해 정렬하는 알고리즘  

#### 퀵 정렬 성능 분석  
 **<정렬된 데이터의 시간복잡도 계산>**  
* 정렬된 데이터가 시간이 가장 적게 걸릴 것으로 예상했으나 오히려 퀵 정렬을 정렬된 데이터에 사용하면 완전 불균형 트리를 형성할 수 있기 때문에 최악의 경우로 판단  
* 트리의 호출 깊이는 n  
* 각 단계(level)마다 n번의 비교
* 이동 횟수 X (비교 횟수보다 작기 때문에 무시 가능)  
* 최종 시간복잡도는 O(n^2)  

 **<정렬된 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 16^2  
* 이동 횟수 16  

 **<랜덤한 데이터의 시간복잡도 계산>**
* 기준 값에 따른 작은 부분, 큰 부분을 나누는 것을 완벽한 균형에 맞추어 트리를 생성할 수는 없으나 약간의 균형이 이루어진 이진 트리를 형성할 수 있으므로
* 각 단계(level)마다 n번의 비교  
* 총 트리의 깊이 log2n  
* 데이터의 이동 및 삽입의 횟수는 무시
* 시간복잡도는 O(nlog2n)  

 **<랜덤한 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 16 log2 16  
* 이동 횟수 16  

 **<역 정렬 데이터의 시간복잡도 계산>**  
* 정렬된 데이터와 유사한 수준으로 이미 역으로 정렬되어 있기 때문에 오히려 불균형 이진 트리가 형성될 수 있음
* 따라서 최종 시간복잡도 O(n^2)  

 **<역 정렬 데이터의 비교 횟수와 이동 횟수>**  
* 비교 횟수 16^2  
* 이동 횟수 16  

___
